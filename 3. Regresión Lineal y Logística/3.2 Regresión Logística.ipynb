{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística\n",
    "Este notebook está hecho para la práctica de regresión logística en Scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para regresión logísitca se requiere\n",
    "* Variable dependiente debe ser categórica o numérica discreta\n",
    "* Si es una regresión logística binaria el valor 1 en la variable dependiente debe ser la categoria deseada\n",
    "* Solo variables significantes deben ser incluídas.\n",
    "* Las variables independintes deben ser independintes entre ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset fue obtenido de UCI Machine Learning repository, y esta relacionado con campañas de marqueting (llamadas telefónicas) de una institución bancaria. El objetivo de la clasificación es prevenir si el cliente va o no a adquirir un CDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En google colaboratory ingresar dentro de una celda\n",
    "```bash\n",
    "!pip install -q pydotplus\n",
    "!apt-get install graphviz\n",
    "```\n",
    "\n",
    "Luego en el menu buscar Entorno de ejecución -> Reiniciar entorno de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "* Cargar el Dataset https://raw.githubusercontent.com/javiercocu/intro-datascience/master/data/bank-additional-full.csv en un DataFrame con la funcion pd.read_csv()\n",
    "* La descripción del dataset se encuentra en: https://archive.ics.uci.edu/ml/datasets/bank+marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_banking = pd.read_csv(\"https://raw.githubusercontent.com/javiercocu/intro-datascience/master/data/bank-additional-full.csv\", sep=\";\")\n",
    "df_banking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_banking.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "Realizar Análisis inicial y estadística descriptiva,\n",
    "* Explore los datos, valores únicos por columna con la funcion unique()\n",
    "* Verificar si hay datos faltantes\n",
    "* Qué se debería hacer con los datos faltantes?\n",
    "* Qué tipo de variables estadísticas son cada una de las características\n",
    "* Use la funcion df_boston.describe() para analizar los principales datos de estadística descriptiva del DataSet\n",
    "* Cree gráficos de histogramas\n",
    "* Cree un gráfico de la matriz de correlación del DataFrame\n",
    "    * ¿Cuáles de las características tienen alta correlación entre ellas?\n",
    "* ¿Cuáles de las caractarísticas tienen más relación con la variable objetivo según diagramas de dispersión?\n",
    "\n",
    "* Incluir dentro del análisis visual para las variables categóricas ('job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome') un gráfico de barras contra variable objetivo\n",
    "\n",
    "```python\n",
    "pd.crosstab(df_banking.job,df_banking.y).plot(kind='bar')\n",
    "plt.title('CDT abiertos por trabajo')\n",
    "plt.xlabel('Trabajo')\n",
    "plt.ylabel('Frecuencia de CDT abiertos')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celdas para completar ejercicio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_banking[\"education\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamiento de valores\n",
    "dic_reemplazo = {'basic.4y':'basic', 'high.school':'basic', 'basic.6y':'basic', 'basic.9y':'basic'}\n",
    "\n",
    "df_banking['education'] = df_banking['education'].replace(dic_reemplazo)\n",
    "df_banking[\"education\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuencias de la variable objetivo\n",
    "df_banking['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por variable objetivo para descubrir posibles relaciones\n",
    "df_banking.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Qué se observa de esta agrupación contra la variable objetivo?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir variables categóricas en uno a muchos\n",
    "\n",
    "# Variables categóricas\n",
    "variables_cat=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "\n",
    "for var_cat in variables_cat:\n",
    "    df_banking2 = df_banking.join(pd.get_dummies(df_banking[var_cat], prefix = var_cat))\n",
    "    df_banking = df_banking2\n",
    "df_banking.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_banking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_columnas = df_banking.columns.tolist()\n",
    "lista_columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_sin_cat = []\n",
    "for columna in lista_columnas:\n",
    "    if columna not in variables_cat:\n",
    "        columnas_sin_cat.append(columna)\n",
    "        \n",
    "columnas_sin_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_banking_final = df_banking[columnas_sin_cat]\n",
    "df_banking_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformación variable objetivo en binario\n",
    "df_banking_final['y'] = df_banking_final['y'].map({'no':0,'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores unicos en variable dependiente\n",
    "df_banking_final['y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datasets de variables independientes X, y variable objetivo Y\n",
    "\n",
    "X = df_banking_final.drop('y', axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_banking_final['y']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('La precisión del modelo de regresión logística en el set de test es:', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada \n",
    "Trata de prevenir el sobreajuste (overfitting) mientras se entrena con todo el dataset.\n",
    "En este caso usaremos 10 divisiones sobre el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"Promedio de precisión sobre validación cruazada: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el promedio de precisión sobre la validación cruzada es cercano a la precisión del modelo, esto quiere decir que el modelo generaliza bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión y exhaustividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión y exhaustividad (denominado a veces como exhaustividad y precisión) es una métrica empleada en la medida del rendimiento de los sistemas de búsqueda y recuperación de información y reconocimiento de patrones. En este contexto se denomina precisión (denominado igualmente valor positivo predicho) como a la fracción de instancias recuperadas que son relevantes, mientras recall (denominado igualmente sensibilidad o exhaustividad) es la fracción de instancias relevantes que han sido recuperadas.1 Tanto la precisión como la exhaustividad son entendidas como medidas de la relevancia. Para entender mejor el concepto, supongamos de la existencia de un programa que reconoce perros en fotografías, dicho programa reconoce 7 perros en una escena que contiene 9 perros y algunos gatos. Si 4 de las identificaciones han sido correctas, pero 3 eran gatos, el programa tendrá una precisión de 4/7 mientras que posee una sensibilidad de 4/9. Otro ejemplo en el que participa un motor de búsqueda que, ante una consulta dada, retorna 30 páginas de las cuales sólo 20 son relevantes dejando 40 páginas relevantes fuera de la búsqueda. Este motor tendrá entonces una precisión de 20/30 = 2/3 mientras que su sensibilidad es 20/60 = 1/3.\n",
    "\n",
    "Para un usuario la situación ideal es aquella en la que existe una precisión y exhaustividad alta (es decir muy cercana a 1). A esta situación se la denomina utilidad teórica. Con el objeto de ponderar y ver cual lejano se encuentran ambas medidas del la utilidad teórica, suele emplearse los valores de ambas métricas combinadas en una media armónica denominada valor-F.\n",
    "\n",
    "(Extraído de wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2\n",
    "### Regresión logística - reconocimiento de dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma del dataset independientes\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "#Forma del dataset variable objetivo\n",
    "print(\"Digitos\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de dígitos\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    " plt.subplot(1, 5, index + 1)\n",
    " plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    " plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir datos de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenar modelo\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir valores no vistos\n",
    "logisticRegr.predict(x_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir múltiples valores\n",
    "logisticRegr.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Pastel1')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "for x in iter(range(width)):\n",
    " for y in iter(range(height)):\n",
    "  plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "  horizontalalignment='center',\n",
    "  verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(y_test, prediction):\n",
    " if label != predict: \n",
    "  misclassifiedIndexes.append(index)\n",
    "  index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
